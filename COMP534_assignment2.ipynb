{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i5afvUbhmGo"
      },
      "source": [
        "---\n",
        "\n",
        "# University of Liverpool\n",
        "\n",
        "## COMP534 - Applied AI\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpEqsZpRKtkE"
      },
      "source": [
        "This notebook is associated with Assignment 2. Use it to complete the assignment by following the instructions provided in each section. Each section includes a text cell outlining the requirements. For additional details, refer to Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGBUHRSKvf1"
      },
      "source": [
        "Use this first cell to import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "taBOSk4HKwZp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "import itertools\n",
        "import random\n",
        "import math\n",
        "import optuna  # We use optuna for hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hglJVRRslqMn"
      },
      "source": [
        "# 1. **Data Management**\n",
        "\n",
        "\n",
        "In this part, you need to:\n",
        "\n",
        "1.  define your experimental protocol (such as k-fold, cross validation, etc)\n",
        "2.\tcreate the dataloader to load the data; remember to include here any normalization, data augmentation, or other technique used to pre-process the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "szQFlMDMJYEh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MPS (Apple Silicon GPU)\n",
            "tensor([[-0.2294, -1.0395, -0.1732],\n",
            "        [-0.2959, -1.1598, -1.4945],\n",
            "        [-0.7959, -0.3982, -0.1433]], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "# First, checking if we can use the Apple Silicon GPU (MPS). If not, check for CUDA; otherwise, we fall back to CPU.\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using MPS (Apple Silicon GPU)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Just a quick test: create a random tensor and move it to our chosen device.\n",
        "x = torch.randn(3, 3).to(device)\n",
        "print(x)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This is a simple wrapper around our dataset that lets us apply a custom transform on a subset.\n",
        "    It takes the original dataset and a list of indices, and optionally a custom transform,\n",
        "    and returns (image, label) pairs for the specified indices.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dataset, indices, custom_transform=None):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.indices = indices\n",
        "        self.custom_transform = custom_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.base_dataset[self.indices[idx]]\n",
        "        if self.custom_transform:\n",
        "            img = self.custom_transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "def get_kfold_loaders(base_dataset, index_list, batch_size, k_folds=5, train_tf=None, val_tf=None):\n",
        "    \"\"\"\n",
        "    This function creates k-fold DataLoaders for training and validation.\n",
        "    We use scikit-learn's KFold to split the provided indices and then create a loader for each fold.\n",
        "    \"\"\"\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "    fold_loaders = []\n",
        "    index_array = np.array(index_list)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(index_array)):\n",
        "        train_indices = index_array[train_idx].tolist()\n",
        "        val_indices = index_array[val_idx].tolist()\n",
        "\n",
        "        train_subset = CustomDataset(base_dataset, train_indices, custom_transform=train_tf)\n",
        "        val_subset = CustomDataset(base_dataset, val_indices, custom_transform=val_tf)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "        fold_loaders.append((train_loader, val_loader))\n",
        "        print(f\"Fold {fold+1}: Train samples = {len(train_subset)}, Val samples = {len(val_subset)}\")\n",
        "\n",
        "    return fold_loaders\n",
        "\n",
        "\n",
        "def load_data(dataset_path, batch_size=32, k_folds=5):\n",
        "    \"\"\"\n",
        "    This function loads the dataset from the given path, splits it into train/val/test sets,\n",
        "    applies appropriate transforms, and returns DataLoaders along with class names.\n",
        "    \"\"\"\n",
        "    # These are the normalization values (using ImageNet statistics here)\n",
        "    mean_vals = [0.485, 0.456, 0.406]\n",
        "    std_vals  = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # Set up data augmentation for training images (256x256)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_vals, std_vals)\n",
        "    ])\n",
        "\n",
        "    # For validation and testing, we just resize and center crop.\n",
        "    val_test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_vals, std_vals)\n",
        "    ])\n",
        "\n",
        "    # Load the dataset (no transforms here yet, we'll apply them later)\n",
        "    full_data = datasets.ImageFolder(root=dataset_path)\n",
        "    total_samples = len(full_data)\n",
        "    indices = list(range(total_samples))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Split the indices: 70% train, 15% validation, and 15% test.\n",
        "    train_end = int(0.7 * total_samples)\n",
        "    val_end = train_end + int(0.15 * total_samples)\n",
        "\n",
        "    train_indices = indices[:train_end]\n",
        "    val_indices = indices[train_end:val_end]\n",
        "    test_indices = indices[val_end:]\n",
        "\n",
        "    # Create k-fold loaders for the training set.\n",
        "    fold_loaders = get_kfold_loaders(full_data, train_indices, batch_size, k_folds,\n",
        "                                     train_tf=train_transform, val_tf=val_test_transform)\n",
        "\n",
        "    # Create DataLoaders for global validation and test sets.\n",
        "    val_dataset = CustomDataset(full_data, val_indices, custom_transform=val_test_transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    test_dataset = CustomDataset(full_data, test_indices, custom_transform=val_test_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"Total samples: {total_samples} | Train: {len(train_indices)}, Val: {len(val_indices)}, Test: {len(test_indices)}\")\n",
        "    print(f\"Classes: {full_data.classes}\")\n",
        "\n",
        "    return fold_loaders, val_loader, test_loader, full_data.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTrpUW8zOp4"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. **Neural Networks**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tpropose your own Convolutional Neural Network (CNN) to tackle the problem;\n",
        "2.\tdefine at least one existing CNN (such as AlexNet, VGG, ResNet, DenseNet, etc) to tackle the problem;\n",
        "3.\tdefine the necessary components to train the networks (that is, loss function, optimizers, etc);\n",
        "4.\ttrain your proposed architecture from scratch using your training set;\n",
        "5.\ttrain the existing architecture using at least 2 different strategies (i.e., trained from scratch, fine-tuning, feature extractor, etc);\n",
        "6.\tfor all training procedures, separately plot the loss and accuracy with respect to the epoch/iteration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jJs8HpW_zX0M"
      },
      "outputs": [],
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    This is our custom CNN model for image classification.\n",
        "    The architecture includes 5 convolutional layers (with increasing channels), each followed by batch norm, ReLU, and max pooling.\n",
        "    After the conv layers, we do global average pooling, then pass the result through a fully connected layer (with dropout)\n",
        "    before the final output layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, channels_mult=1.0, fc_size=128, dropout_rate=0.5):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        # Layer 1: Convolution, BatchNorm, ReLU, and MaxPool (256 -> 128)\n",
        "        self.conv1 = nn.Conv2d(3, int(16 * channels_mult), kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(int(16 * channels_mult))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Layer 2: Convolution, BatchNorm, ReLU, and MaxPool (128 -> 64)\n",
        "        self.conv2 = nn.Conv2d(int(16 * channels_mult), int(32 * channels_mult), kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(int(32 * channels_mult))\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Layer 3: Convolution, BatchNorm, ReLU, and MaxPool (64 -> 32)\n",
        "        self.conv3 = nn.Conv2d(int(32 * channels_mult), int(64 * channels_mult), kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(int(64 * channels_mult))\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Layer 4: Convolution, BatchNorm, ReLU, and MaxPool (32 -> 16)\n",
        "        self.conv4 = nn.Conv2d(int(64 * channels_mult), int(128 * channels_mult), kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(int(128 * channels_mult))\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Layer 5: Convolution, BatchNorm, ReLU, and MaxPool (16 -> 8)\n",
        "        self.conv5 = nn.Conv2d(int(128 * channels_mult), int(256 * channels_mult), kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(int(256 * channels_mult))\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Global average pooling to reduce to 1x1 feature map\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        # Fully connected layer: first FC then dropout then final FC\n",
        "        self.fc1 = nn.Linear(int(256 * channels_mult), fc_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.bn1(self.conv1(x))))    # 256 -> 128\n",
        "        x = self.pool2(self.relu(self.bn2(self.conv2(x))))     # 128 -> 64\n",
        "        x = self.pool3(self.relu(self.bn3(self.conv3(x))))     # 64 -> 32\n",
        "        x = self.pool4(self.relu(self.bn4(self.conv4(x))))     # 32 -> 16\n",
        "        x = self.pool5(self.relu(self.bn5(self.conv5(x))))     # 16 -> 8\n",
        "        x = self.global_pool(x)                                # Resulting shape: (B, channels, 1, 1)\n",
        "        x = x.view(x.size(0), -1)                              # Flatten to (B, channels)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_resnet18_model(num_classes, strategy=\"finetune\"):\n",
        "    \"\"\"\n",
        "    This function loads a ResNet18 model. Depending on the strategy, it either loads a pre-trained model for fine-tuning,\n",
        "    or loads it as a feature extractor (freezing all layers except the final one). Finally, it replaces the last FC layer\n",
        "    with one that outputs the required number of classes.\n",
        "    \"\"\"\n",
        "    if strategy == \"scratch\":\n",
        "        net = models.resnet18(pretrained=False)\n",
        "    else:\n",
        "        net = models.resnet18(pretrained=True)\n",
        "\n",
        "    if strategy == \"feature_extractor\":\n",
        "        for param in net.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Update the final fully connected layer to match our number of classes\n",
        "    num_features = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_label=\"Model\"):\n",
        "    \"\"\"\n",
        "    This function trains the given model for a number of epochs.\n",
        "    It also plots the training and validation loss and accuracy curves.\n",
        "    \"\"\"\n",
        "    # We use a StepLR scheduler to decay the learning rate every 3 epochs\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Loop through the training data\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(predictions == labels.data)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / total_samples\n",
        "        epoch_acc = running_corrects.double() / total_samples\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_acc\"].append(epoch_acc.item())\n",
        "\n",
        "        # Evaluate on the validation set\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predictions = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(predictions == labels.data)\n",
        "                total_val += images.size(0)\n",
        "\n",
        "        epoch_val_loss = val_loss / total_val\n",
        "        epoch_val_acc = val_corrects.double() / total_val\n",
        "        history[\"val_loss\"].append(epoch_val_loss)\n",
        "        history[\"val_acc\"].append(epoch_val_acc.item())\n",
        "\n",
        "        print(f\"{model_label} Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc*100:.2f}% | \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc*100:.2f}%\", flush=True)\n",
        "\n",
        "        # Keep track of the best model based on validation accuracy\n",
        "        if epoch_val_acc > best_acc:\n",
        "            best_acc = epoch_val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        scheduler.step()  # Update the learning rate\n",
        "\n",
        "    # Load the best model weights we found\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Plot the loss curves for training and validation\n",
        "    epochs_range = range(1, num_epochs + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, history[\"train_loss\"], label=\"Train Loss\", color='blue')\n",
        "    plt.plot(epochs_range, history[\"val_loss\"], label=\"Val Loss\", color='red')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"{model_label} Loss Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot the accuracy curves for training and validation\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, history[\"train_acc\"], label=\"Train Accuracy\", color='green')\n",
        "    plt.plot(epochs_range, history[\"val_acc\"], label=\"Val Accuracy\", color='orange')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"{model_label} Accuracy Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    This function evaluates the model on the test set.\n",
        "    It calculates the average loss, accuracy, as well as precision, recall, and F1 score.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_test = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            correct_preds += torch.sum(predictions == labels.data)\n",
        "            total_test += images.size(0)\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = test_loss / total_test\n",
        "    test_accuracy = correct_preds.double() / total_test\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    print(f\"\\nTest Loss: {avg_loss:.4f} | Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "    return avg_loss, test_accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(model, test_loader, class_names, device):\n",
        "    \"\"\"\n",
        "    This function computes predictions on the test data and plots the confusion matrix.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=90, fontweight='normal', fontstyle='normal')\n",
        "    plt.yticks(tick_marks, class_names, fontweight='normal', fontstyle='normal')\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in np.ndindex(cm.shape):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hyperband_search(train_loader, val_loader, num_classes, device, max_trials=10, epochs=10):\n",
        "    \"\"\"\n",
        "    This function performs a simple Hyperband-style search for hyperparameters for our custom CNN.\n",
        "    It runs for a fixed number of trials and returns the best hyperparameters found.\n",
        "    \"\"\"\n",
        "    best_val_acc = 0.0\n",
        "    best_params = {}\n",
        "\n",
        "    for trial in range(max_trials):\n",
        "        channels_mult = random.choice([0.5, 1.0, 1.5, 2.0])\n",
        "        fc_size = random.choice([64, 128, 256])\n",
        "        dropout_rate = random.choice([0.3, 0.5, 0.7])\n",
        "        lr = random.choice([0.0001, 0.001, 0.01])\n",
        "        # Pick a weight decay value from a loguniform distribution between 1e-5 and 1e-3\n",
        "        weight_decay = math.exp(random.uniform(math.log(1e-5), math.log(1e-3)))\n",
        "        print(f\"\\nHyperband Trial {trial+1}: channels_mult={channels_mult}, fc_size={fc_size}, dropout_rate={dropout_rate}, lr={lr}, weight_decay={weight_decay:.5f}\")\n",
        "\n",
        "        model = CustomCNN(num_classes, channels_mult=channels_mult, fc_size=fc_size, dropout_rate=dropout_rate).to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # Use AdamW optimizer with the sampled weight decay\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        # Train the model for a few epochs to see how it performs\n",
        "        model, history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device,\n",
        "                                     model_label=f\"Hyperband Trial {trial+1}\")\n",
        "        trial_val_acc = history[\"val_acc\"][-1]\n",
        "        print(f\"Hyperband Trial {trial+1} Validation Accuracy: {trial_val_acc*100:.2f}%\")\n",
        "\n",
        "        if trial_val_acc > best_val_acc:\n",
        "            best_val_acc = trial_val_acc\n",
        "            best_params = {\"channels_mult\": channels_mult, \"fc_size\": fc_size, \"dropout_rate\": dropout_rate, \"lr\": lr, \"weight_decay\": weight_decay}\n",
        "\n",
        "    print(\"\\nBest Hyperparameters:\", best_params, \"\\nWith validation accuracy:\", best_val_acc*100, \"%\")\n",
        "    return best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RBW58of0ZDo"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. **Evaluate models**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tevaluate the model (the best one you obtained in the above stage) on the testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHWwdXg32BEl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Fold 1: Train samples = 1176, Val samples = 294\n",
            "Fold 2: Train samples = 1176, Val samples = 294\n",
            "Fold 3: Train samples = 1176, Val samples = 294\n",
            "Fold 4: Train samples = 1176, Val samples = 294\n",
            "Fold 5: Train samples = 1176, Val samples = 294\n",
            "Total samples: 2100 | Train: 1470, Val: 315, Test: 315\n",
            "Classes: ['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', 'forest', 'freeway', 'golfcourse', 'harbor', 'intersection', 'mediumresidential', 'mobilehomepark', 'overpass', 'parkinglot', 'river', 'runway', 'sparseresidential', 'storagetanks', 'tenniscourt']\n",
            "\n",
            "Running Hyperband Search for Custom CNN model...\n",
            "\n",
            "Hyperband Trial 1: channels_mult=2.0, fc_size=128, dropout_rate=0.5, lr=0.001, weight_decay=0.00001\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Main script: set up our device (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Define some parameters for our experiment\n",
        "    dataset_directory = \"Images\"\n",
        "    batch_size_val = 32\n",
        "    num_epochs_val = 5\n",
        "    k_folds_val = 5\n",
        "    \n",
        "\n",
        "    # Load the dataset and get our DataLoaders for training, validation, and testing\n",
        "    folds, val_loader_global, test_loader, class_list = load_data(dataset_directory, batch_size=batch_size_val, k_folds=k_folds_val)\n",
        "    num_classes = len(class_list)\n",
        "\n",
        "    # For simplicity, we use the first fold for training and validation\n",
        "    train_loader_fold, val_loader_fold = folds[0]\n",
        "\n",
        "    # Run Hyperband search to get good hyperparameters for our custom CNN\n",
        "    print(\"\\nRunning Hyperband Search for Custom CNN model...\")\n",
        "    best_params = hyperband_search(train_loader_fold, val_loader_fold, num_classes, device, max_trials=10, epochs=10)\n",
        "\n",
        "    # Train our Custom CNN from scratch using the best hyperparameters found\n",
        "    print(\"\\nNow training Custom CNN with Best Hyperparameters from Hyperband...\")\n",
        "    custom_net = CustomCNN(num_classes, channels_mult=best_params[\"channels_mult\"],\n",
        "                           fc_size=best_params[\"fc_size\"], dropout_rate=best_params[\"dropout_rate\"]).to(device)\n",
        "    criterion_custom = nn.CrossEntropyLoss()\n",
        "    optimizer_custom = optim.AdamW(custom_net.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n",
        "    custom_net, history_custom = train_model(custom_net, train_loader_fold, val_loader_fold,\n",
        "                                             criterion_custom, optimizer_custom, num_epochs_val, device,\n",
        "                                             model_label=\"Custom CNN\")\n",
        "\n",
        "    # Train ResNet18 using fine-tuning\n",
        "    print(\"\\nNow training ResNet18 with Fine-tuning...\")\n",
        "    resnet_finetune = get_resnet18_model(num_classes, strategy=\"finetune\").to(device)\n",
        "    criterion_resnet = nn.CrossEntropyLoss()\n",
        "    optimizer_resnet = optim.Adam(resnet_finetune.parameters(), lr=0.001)\n",
        "    resnet_finetune, history_resnet_ft = train_model(resnet_finetune, train_loader_fold, val_loader_fold,\n",
        "                                                     criterion_resnet, optimizer_resnet, num_epochs_val, device,\n",
        "                                                     model_label=\"ResNet18 Fine-tune\")\n",
        "\n",
        "    # Train ResNet18 as a Feature Extractor (only update the final layer)\n",
        "    print(\"\\nNow training ResNet18 as a Feature Extractor...\")\n",
        "    resnet_feat = get_resnet18_model(num_classes, strategy=\"feature_extractor\").to(device)\n",
        "    optimizer_resnet_feat = optim.Adam(resnet_feat.fc.parameters(), lr=0.001)\n",
        "    resnet_feat, history_resnet_feat = train_model(resnet_feat, train_loader_fold, val_loader_fold,\n",
        "                                                   criterion_resnet, optimizer_resnet_feat, num_epochs_val, device,\n",
        "                                                   model_label=\"ResNet18 Feature Extractor\")\n",
        "\n",
        "    # Print validation accuracies for all models\n",
        "    best_val_acc_custom = history_custom[\"val_acc\"][-1]\n",
        "    best_val_acc_ft = history_resnet_ft[\"val_acc\"][-1]\n",
        "    best_val_acc_feat = history_resnet_feat[\"val_acc\"][-1]\n",
        "\n",
        "    print(\"\\nValidation Accuracy Comparison of the three models:\")\n",
        "    print(f\"Custom CNN: {best_val_acc_custom*100:.2f}%\")\n",
        "    print(f\"ResNet18 (Fine-tune): {best_val_acc_ft*100:.2f}%\")\n",
        "    print(f\"ResNet18 (Feature Extractor): {best_val_acc_feat*100:.2f}%\")\n",
        "\n",
        "    # Plot confusion matrices for each model\n",
        "    print(\"\\nPlotting Confusion Matrix for Custom CNN...\")\n",
        "    plot_confusion_matrix(custom_net, test_loader, class_list, device)\n",
        "\n",
        "    print(\"\\nPlotting Confusion Matrix for ResNet18 Fine-tune...\")\n",
        "    plot_confusion_matrix(resnet_finetune, test_loader, class_list, device)\n",
        "\n",
        "    print(\"\\nPlotting Confusion Matrix for ResNet18 Feature Extractor...\")\n",
        "    plot_confusion_matrix(resnet_feat, test_loader, class_list, device)\n",
        "\n",
        "    # Choose the best model based on the highest validation accuracy\n",
        "    best_model = custom_net\n",
        "    best_model_name = \"Custom CNN\"\n",
        "    if best_val_acc_ft > best_val_acc_custom and best_val_acc_ft > best_val_acc_feat:\n",
        "        best_model = resnet_finetune\n",
        "        best_model_name = \"ResNet18 Fine-tune\"\n",
        "    elif best_val_acc_feat > best_val_acc_custom and best_val_acc_feat > best_val_acc_ft:\n",
        "        best_model = resnet_feat\n",
        "        best_model_name = \"ResNet18 Feature Extractor\"\n",
        "    print(f\"\\nSelected Best Model out of three:- {best_model_name}\")\n",
        "\n",
        "    # Evaluate the best model on the test set and print all the metrics\n",
        "    print(f\"\\nEvaluating the best model: {best_model_name} on the Test Set...\")\n",
        "    test_loss, test_accuracy, precision, recall, f1 = evaluate_model(best_model, test_loader, criterion_resnet, device)\n",
        "    print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "    print(f\"Test Precision: {precision*100:.2f}%\")\n",
        "    print(f\"Test Recall: {recall*100:.2f}%\")\n",
        "    print(f\"Test F1 Score: {f1*100:.2f}%\")\n",
        "\n",
        "    # Plot confusion matrix for the best model\n",
        "    print(f\"\\nPlotting Confusion Matrix for the Best Model: {best_model_name}...\")\n",
        "    plot_confusion_matrix(best_model, test_loader, class_list, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
